{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INTRODUCTION\n",
        "\n",
        "This project aims to classify emails as spam or not spam. The dataset the model is trained on is retrieved from the kaggle website.Throughout the project , I will be explaining my workflow through comments or text boxes . This is my second project in this field . Hopefully , it succeeds !"
      ],
      "metadata": {
        "id": "giMl2hDlN4oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABOUT THE DATASET\n",
        "\n",
        "The dataset can be easily accessed from the following link :\n",
        "https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv/data\n",
        "\n",
        "This data consists of 3002 columns and 5172 rows , each row representing an email.\n",
        "\n",
        "The columns consist of the Email number , the various words used in the emails and finally a prediction column that decides whether an email is spam or not.\n",
        "\n"
      ],
      "metadata": {
        "id": "QTw1nqnMOoDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEPS OF EXECUTION OF THE PROJECT\n",
        "\n",
        "\n",
        "1.   Import the modules\n",
        "1.   Load the data\n",
        "2.   Understand the data\n",
        "3.   Prepare the data\n",
        "4.   Split the data\n",
        "5.   Scaling , training and evaluating models\n",
        "6.   Selecting the model\n",
        "8.   Deploy the model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cnfdr4uPQbk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTING MODULES"
      ],
      "metadata": {
        "id": "T2XpT6eSRTqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing all the necessary modules\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_score , recall_score\n",
        "from sklearn.metrics import f1_score , roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve , roc_curve\n",
        "import joblib"
      ],
      "metadata": {
        "id": "HAxn7So5Rgub"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING , UNDERSTANDING , SPLITTING AND PREPARING THE DATA\n",
        "\n"
      ],
      "metadata": {
        "id": "QRcjN71DSPkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "\n",
        "emails = pd.read_csv(\"Emails_Dataset.csv\")"
      ],
      "metadata": {
        "id": "0zfa5-rvSbYf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Understanding the data\n",
        "\n",
        "print (\"Number of null values in each column :-\")\n",
        "print(emails.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVrCSlfWSqJ-",
        "outputId": "bf83c680-10d1-484d-d468-65e5514b4bb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values in each column :-\n",
            "Email No.     0\n",
            "the           0\n",
            "to            0\n",
            "ect           0\n",
            "and           0\n",
            "             ..\n",
            "military      0\n",
            "allowing      0\n",
            "ff            0\n",
            "dry           0\n",
            "Prediction    0\n",
            "Length: 3002, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing and Splitting the data\n",
        "\n",
        "#Cleaning and creating features and target values\n",
        "emails_train = emails.drop([\"Email No.\",\"Prediction\"],axis=1)\n",
        "emails_prediction = emails[\"Prediction\"]\n",
        "\n",
        "strat_emails_train,strat_emails_test,strat_emails_prediction_train,strat_emails_prediction_test = train_test_split(emails_train,emails_prediction,test_size=0.2,random_state=42,stratify=emails_prediction)"
      ],
      "metadata": {
        "id": "4wC9HUDVVRW9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCALING (ACCORDING TO MODEL) AND TRAINING ON DATA"
      ],
      "metadata": {
        "id": "PTbFh_SrmPWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling and training the logistic regression model\n",
        "\n",
        "log_reg_pipeline = Pipeline([('std_scaler',StandardScaler()),\n",
        "                            ('log_regression',LogisticRegression(C=0.35938137,max_iter = 10000))])\n",
        "scores = cross_val_score(log_reg_pipeline,strat_emails_train,strat_emails_prediction_train,cv=5,scoring='accuracy',n_jobs=-1)\n",
        "print(scores)\n",
        "print (\"Average Score : \",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbERTF0kj8yD",
        "outputId": "bb4fe925-184f-43b1-b852-3ed31c39fc84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.97342995 0.96980676 0.9637243  0.96977025 0.96251511]\n",
            "Average Score :  0.9678492776989176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling and training the k neighbors classifier model\n",
        "\n",
        "kn_classifier_pipeline = Pipeline([('std_scaler',StandardScaler()),\n",
        "                            ('kn_classifier',KNeighborsClassifier(n_neighbors=2,weights='uniform'))])\n",
        "scores = cross_val_score(kn_classifier_pipeline,strat_emails_train,strat_emails_prediction_train,cv=5,scoring='accuracy',n_jobs=-1)\n",
        "print(scores)\n",
        "print (\"Average Score : \",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9xIZucAtTnm",
        "outputId": "c16ba147-7b27-42b9-a77d-2a5017b6372f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.87439614 0.8647343  0.88270859 0.86457074 0.87908102]\n",
            "Average Score :  0.8730981546711529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling and training the random forest classifier model\n",
        "\n",
        "random_forest_pipeline = Pipeline([\n",
        "                            ('rf_classifier',RandomForestClassifier(random_state=42))])\n",
        "scores = cross_val_score(random_forest_pipeline,strat_emails_train,strat_emails_prediction_train,cv=5,scoring='accuracy',n_jobs=-1)\n",
        "print(scores)\n",
        "print (\"Average Score : \",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD20yaUdvOcD",
        "outputId": "d6648b33-915c-4765-a469-6797025c4f16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96859903 0.97826087 0.96977025 0.96614268 0.95646917]\n",
            "Average Score :  0.9678484014743939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling and training the stochastic gradient descent classifier model\n",
        "\n",
        "sgd_classifier_pipeline = Pipeline([('std_scaler',StandardScaler()),\n",
        "                            ('sgd_classifier',SGDClassifier(random_state=42))])\n",
        "scores = cross_val_score(sgd_classifier_pipeline,strat_emails_train,strat_emails_prediction_train,cv=5,scoring='accuracy',n_jobs=-1)\n",
        "print(scores)\n",
        "print (\"Average Score : \",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAGHFV1Pv79i",
        "outputId": "86578da0-a6e9-4167-c4e2-1051a5fb3b40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96376812 0.93236715 0.91051995 0.96493349 0.94679565]\n",
            "Average Score :  0.9436768717616204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL MODEL SELECTED : LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "geaDYwF1IU1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the Logistic Regression Model\n",
        "log_reg_pipeline = Pipeline([('std_scaler',StandardScaler()),\n",
        "                            ('log_regression',LogisticRegression(C=0.35938137,max_iter = 10000))])\n",
        "log_reg_pipeline.fit(strat_emails_train,strat_emails_prediction_train)\n",
        "predictions=log_reg_pipeline.predict(strat_emails_test)\n",
        "accuracy = (predictions==strat_emails_prediction_test).mean()\n",
        "print(\"Accuracy of the model :-\",accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5XBe4byInc2",
        "outputId": "81af4afc-ed68-4d90-c7d2-16eeaba37917"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model :- 0.9729468599033816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATING PRECISION , RECALL ,F1 AND AUC SCORES OF THE MODEL\n"
      ],
      "metadata": {
        "id": "3OB-TQw6dPFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding out the precision\n",
        "\n",
        "precision = precision_score(strat_emails_prediction_test,predictions)\n",
        "print(\"Precision:\",precision)\n",
        "\n",
        "#Finding out the recall of the model\n",
        "recall = recall_score(strat_emails_prediction_test,predictions)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "#Finding out the area under the receiver operating characteristic curve (recall vs fpr)\n",
        "auc = roc_auc_score(strat_emails_prediction_test,predictions)\n",
        "print(\"Area under curve:\",auc)\n",
        "\n",
        "f1_score = f1_score(strat_emails_prediction_test,predictions)\n",
        "print(\"F1 Score :\",f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9qxD45VdnWb",
        "outputId": "8fa1ba5c-7d37-4a31-fcbe-4f3e2fd4cf49"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9331210191082803\n",
            "Recall: 0.9766666666666667\n",
            "Area under curve: 0.9740476190476189\n",
            "F1 Score : 0.9543973941368078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEPLOY THE TRAINED MODEL"
      ],
      "metadata": {
        "id": "gAwMw2A_uhby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deploying the model\n",
        "joblib.dump(log_reg_pipeline , \"Srihari_Spam_Classifier_1.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4b_OyfDuljc",
        "outputId": "deeaf250-a863-4f04-e3d0-bf0d0f015406"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Srihari_Spam_Classifier_1.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONCLUSION\n",
        "\n",
        "This concludes the first round of classifying emails as spam or not spam. While this is just a starter , accuracies have been a complete satisfaction . Vectorization hasn't been explicitly shown here since data is already vectorized . TF-IDF weights could be easily added with python functions , but evaluations suggested poorer performance due to high regularization (overgeneralization). For example , the accuracy of the logistic regression model dropped from a whopping 0.97 to mere 0.68 . Automatic tuning of hyperparameters has also been done , but not depicted here for simplicity and cleanliness . Training has only been done on a few models . However , in the upcoming versions of this project , incorporations of neural networks and other complex ML models are definite . So , stay tuned !"
      ],
      "metadata": {
        "id": "NyTNXFZ1hUyl"
      }
    }
  ]
}